# run
task: offline_generalization
setting: qm9str


# wandb
wandb_mode: disabled   # online, offline, disabled
wandb_project: logit-gfn
wandb_entity: 'anonymous'

temp_cond: false
temp_cond_type: logit # logit, layer

# layer-conditioning for logit-gfn
layer_conditioning: false

# thermometer encoding for layer-gfn
thermometer: false
num_thermometer_dim: 32

# loss_type
loss_type: tb # tb, db, subtb
# lambda for subtb
lamda: 0.9

# temperature distributions
target_beta: 1

train_temp_dist: uniform # constant, uniform, loguniform, expuniform, normal, annealing, annealing-inv
train_temp: 1
train_temp_min: 10
train_temp_max: 50
train_temp_mu: 2
train_temp_sigma: 0.5

exp_temp_dist: uniform # constant, uniform, loguniform, expuniform, normal, annealing, annealing-inv
exp_temp: 1
exp_temp_min: 10
exp_temp_max: 50
exp_temp_mu: 2
exp_temp_sigma: 0.5

# seed for reproduction
seed: 0

# model learning
lr_z: 1.0e-2
lr_policy: 1.0e-4
lr_critic: 1.0e-4
lr_logF: 1.0e-4
clip_policy_logit_min: -20.0
clip_policy_logit_max: 20.0
clip_grad_norm: 10.0
clip_param: 0.2
init_logz: false

# model architecture
sa_or_ssr: ssr
sa_hid_dim: 1024
sa_n_layers: 1
ssr_encoder_hid_dim: 1024
ssr_encoder_n_layers: 1
ssr_embed_dim: 1024
ssr_scorer_hid_dim: 1024
ssr_scorer_n_layers: 1

# model architectures (for temperatures)
ssr_temp_cond_hid_dim: 32
ssr_temp_cond_n_layers: 2


# trainer
num_offline_training_rounds: 1000
num_samples_per_offline_batch: 32

num_steps_per_batch: 1
num_offline_batches_per_round: 1

prt: true
explore_epsilon: 0.10

# logging
save_models_dir: saved_models/qm9str/
save_every_x_active_rounds: 200

monitor_num_samples: 128
monitor_fast_every: 10
monitor_slow_every: 200
monitor_real_samples: true

# query
query_num_samples: 2048
query_values: 1,5,10,50,100,500,1000

# reward exponent and normalization constant
scale_reward_min: 0.001
scale_reward_max: 100
reward_exp: 5

# experiment-specific settings
blocks_file: datasets/qm9str/block_qm9str_v1.json
x_to_r_file: datasets/qm9str/block_qm9str_v1_s5.pkl
mode_file: datasets/qm9str/modes_qm9str.pkl
forced_stop_len: 5
